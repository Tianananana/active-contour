{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Active Contour.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tianananana/active-contour/blob/main/Active_Contour.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6s-UNO4GU5Y"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from torch.autograd.functional import jacobian\n",
        "from torchvision import transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGNRS24i8FGy",
        "cellView": "code"
      },
      "source": [
        "def bilinear_interpolation(coord, img):\n",
        "  \"\"\"\n",
        "  Bilinear interpolation.\n",
        "  :param coord: coord of points\n",
        "  :param img: 2d array of smoothed img\n",
        "  \"\"\"\n",
        "  x = coord[:, 0]\n",
        "  y = coord[:, 1]\n",
        "  \n",
        "  x1, x2 = torch.floor(x).type(torch.long), torch.ceil(x).type(torch.long)\n",
        "  y1, y2 = torch.floor(y).type(torch.long), torch.ceil(y).type(torch.long)\n",
        "\n",
        "  # 1st condition x1!=x2 and y1!=y2\n",
        "  q11, q12, q21, q22 = img[x1, y1], img[x2, y1], img[x1, y2], img[x2, y2]\n",
        "  interp_px = (q11 * (x2 - x) * (y2 - y) +\n",
        "               q21 * (x - x1) * (y2 - y) +\n",
        "               q12 * (x2 - x) * (y - y1) +\n",
        "               q22 * (x - x1) * (y - y1)\n",
        "               )\n",
        "  \n",
        "  # get the index of x1==x2 , y1==y2 respectively\n",
        "  index_x = x1==x2\n",
        "  index_y = y1==y2\n",
        "\n",
        "  # 2ed condition x1==x2 and y1==y2\n",
        "  interp_px[index_x & index_y]  = img[x1, y1][index_x & index_y]\n",
        "\n",
        "  # 3rd condition x1!=x2 and y1==y2\n",
        "  interp_px[~index_x & index_y]  = ((x2-x)*q11 + (x-x1)*q12)[~index_x & index_y]\n",
        "\n",
        "  # 4th condition x1==x2 and y1!=y2\n",
        "  interp_px[index_x & ~index_y]  = ((y2-y)*q11 + (y-y1)*q21)[index_x & ~index_y]\n",
        "     \n",
        "  return interp_px"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELk1g3H7OKqx"
      },
      "source": [
        "class ActiveContourImg:\n",
        "  def __init__(self, img, coord, alpha=0.1, epsilon=0.01, lr=0.01):\n",
        "    # Assume input img and coord is tensor when instantiating ActiveConourImg\n",
        "    self.img = img\n",
        "    k = 7\n",
        "    s = 5\n",
        "\n",
        "    # Gaussian blur via cv2 \n",
        "    # self.smooth = cv2.GaussianBlur(self.img.detach().numpy(), (k, k), s)\n",
        "    # self.smooth = torch.from_numpy(self.smooth).type(torch.FloatTensor)\n",
        "\n",
        "    # Gaussian blur via torchvision transforms\n",
        "    data_transforms = transforms.Compose([transforms.GaussianBlur(k, sigma=(s))])\n",
        "    self.smooth = data_transforms(self.img)\n",
        "    self.smooth = torch.clamp(self.img, min=1e-10, max=255)\n",
        "\n",
        "    # Get image gradients\n",
        "    self.dx_img = 1/8 * cv2.Sobel(self.smooth.detach().numpy(), cv2.CV_64F, 1, 0, ksize=3)\n",
        "    self.dx_img = torch.from_numpy(self.dx_img).type(torch.FloatTensor)\n",
        "    \n",
        "    self.dy_img = 1/8 * cv2.Sobel(self.smooth.detach().numpy(), cv2.CV_64F, 0, 1, ksize=3)\n",
        "    self.dy_img = torch.from_numpy(self.dy_img).type(torch.FloatTensor)\n",
        "\n",
        "\n",
        "    self.no_pts = coord.shape[0]\n",
        "\n",
        "\n",
        "    # Calculate l_0:\n",
        "    self.pa = coord[0, :] # start pt\n",
        "    self.pb = coord[-1, :] # end pt\n",
        "    l_total = torch.norm(self.pa - self.pb)\n",
        "    self.l_0 = (l_total/(self.no_pts-1)).item()\n",
        "\n",
        "    # Parameters\n",
        "    self.epsilon = epsilon\n",
        "    self.alpha = alpha\n",
        "    self.lr = lr\n",
        "    self.P_reg = (self.img[self.pa.type(torch.IntTensor)[0],self.pa.type(torch.IntTensor)[1]] + \\\n",
        "                  self.img[self.pb.type(torch.IntTensor)[0],self.pb.type(torch.IntTensor)[1]])/2 # eqn (6) of paper\n",
        "\n",
        "    # To be initialised. dtype: torch.\n",
        "    self.l = None\n",
        "    self.g = None\n",
        "    self.j_l = None\n",
        "    self.j_g = None\n",
        "    self.loss = None\n",
        "    \n",
        "\n",
        "  def update_l(self, coord):\n",
        "    \"\"\"\n",
        "    Updates value of l. Shape: (no_pts - 1, 1)\n",
        "    \"\"\"\n",
        "    return torch.norm(coord[1:, :] - coord[:-1, :], dim = -1)\n",
        "\n",
        "   \n",
        "  def update_g(self,interp_px):\n",
        "    \"\"\"\n",
        "    Updates value of g: Shape: (no_pts - 1, 1)\n",
        "    \"\"\"\n",
        "    return (interp_px[:-1] + self.epsilon)**(-1) + (interp_px[1:] + self.epsilon)**(-1)\n",
        "\n",
        "\n",
        "\n",
        "  def update_j_l(self):\n",
        "    \"\"\"\n",
        "    Set new value of j_l and j_g. Shape: (no_pts - 1, no_pts, 2).\n",
        "    j_l calculated via pytorch's jacobian method.\n",
        "    \"\"\"\n",
        "    return jacobian(self.update_l, self.coord)\n",
        "\n",
        "\n",
        "  def update_j_g(self, interp_px, interp_px_dx, interp_px_dy):\n",
        "    \"\"\"\n",
        "    Set new value of j_g. Shape: (no_pts - 1, no_pts, 2).\n",
        "    j_g calculated from dx_img and dy_img.\n",
        "    \"\"\"\n",
        "    vx = - torch.diag(interp_px_dx/(interp_px + self.epsilon)**2) # k = i-1\n",
        "    vy = - torch.diag(interp_px_dy/(interp_px + self.epsilon)**2)\n",
        "    \n",
        "    jx_g = vx[:-1,:]+vx[1:,:]\n",
        "    jy_g = vy[:-1,:]+vy[1:,:]\n",
        "\n",
        "    return torch.stack((jx_g, jy_g), axis = -1)\n",
        "\n",
        "\n",
        "  def dL1dr(self):\n",
        "    \"\"\"\n",
        "    Compute first term of loss function. Returns tensor of shape (no_pts, 2)\n",
        "    \"\"\"\n",
        "    grad_x = np.matmul(self.j_g[:, :, 0].T, self.l) + np.matmul(self.j_l[:, :, 0].T, self.g)\n",
        "    grad_y = np.matmul(self.j_g[:, :, 1].T, self.l) + np.matmul(self.j_l[:, :, 1].T, self.g)\n",
        "    return torch.stack((grad_x, grad_y), axis = -1)\n",
        "\n",
        "  def dL2dr(self):\n",
        "    \"\"\"\n",
        "    Compute second term of loss function. Returns tensor of shape (no_pts-2, 2)\n",
        "    # Exclude out 1st and n-th point\n",
        "    \"\"\"  \n",
        "    coord = self.coord[1:-1,:]\n",
        "    coord.requires_grad = True\n",
        "    li_loss = torch.sum(((torch.norm(coord[1:, :] - coord[:-1, :], dim=1)) - self.l_0)**2)+\\\n",
        "        ((torch.norm(coord[0, :] - self.pa)) - self.l_0)**2+\\\n",
        "        ((torch.norm(self.pb - coord[-1, :])) - self.l_0)**2\n",
        "\n",
        "    li_loss.backward()\n",
        "    return coord.grad\n",
        "\n",
        "\n",
        "  def grad_descent(self):\n",
        "    return self.dL1dr()[1:-1, :] + self.alpha*self.dL2dr()\n",
        "\n",
        "\n",
        "  def update_coord(self):\n",
        "    updated_coord = self.coord[1:-1, :]  - self.lr*self.grad_descent()\n",
        "    self.coord[1:-1] = updated_coord\n",
        "   \n",
        "\n",
        "  def loss_calculation(self, interp_px):\n",
        "    loss_1= torch.sum(self.l/(interp_px[:-1] + self.epsilon)+self.l/(interp_px[1:] + self.epsilon))*self.P_reg/2\n",
        "    loss_2 = torch.sum((self.l - self.l_0)**2)\n",
        "    return torch.sum(loss_1) + self.alpha*torch.sum(loss_2)\n",
        "    \n",
        "\n",
        "\n",
        "  def train_one_round(self):\n",
        "    interp_px = bilinear_interpolation(self.coord,self.img)\n",
        "    interp_px_dx = bilinear_interpolation(self.coord,self.dx_img)\n",
        "    interp_px_dy = bilinear_interpolation(self.coord,self.dy_img)\n",
        "    self.l = self.update_l(self.coord)\n",
        "    self.g = self.update_g(interp_px)\n",
        "    self.j_l = self.update_j_l()\n",
        "    self.j_g = self.update_j_g(interp_px,interp_px_dx,interp_px_dy)\n",
        "    self.loss = self.loss_calculation(interp_px)\n",
        "    self.update_coord()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP3loYbA_8na"
      },
      "source": [
        "def main(img, coord, rounds=10, alpha=0.1, epsilon = 0.01, lr=0.01):\n",
        "  image = ActiveContourImg(img, coord)\n",
        "\n",
        "  loss_all = []\n",
        "  \n",
        "  for i in range(rounds):\n",
        "    print(\"round:{}==============\".format(i))\n",
        "    image.train_one_round()\n",
        "    print(\"loss:\", image.loss)\n",
        "    loss_all.append(image.loss)\n",
        "  print(\"Final coord: {} ============= All loss: {}\".format(image.curr_coord, np.array(loss_all)))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(img, coord)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY3ydSU_G2N-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c853d61-65dd-40d7-f17b-adf98691110f"
      },
      "source": [
        "# TEST #\n",
        "## Initialise coord and img ##\n",
        "coord = torch.arange(start=30, end=70, step=2).reshape(10, 2).type(torch.FloatTensor)\n",
        "img = torch.zeros((100, 100)).type(torch.FloatTensor)\n",
        "for i in range(100):\n",
        "  img[i, :] = torch.arange(100)\n",
        "coord += 0.5\n",
        "\n",
        "print(\"Coord Shape: {}\".format(coord.shape))\n",
        "print(\"Image Shape: {}\".format(img.shape))\n",
        "print(\"Coord Type: {}\".format(type(coord)))\n",
        "print(\"Image Type: {}\".format(type(img)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coord Shape: torch.Size([10, 2])\n",
            "Image Shape: torch.Size([100, 100])\n",
            "Coord Type: <class 'torch.Tensor'>\n",
            "Image Type: <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGpT79Pp_1ZU",
        "outputId": "6a2d7028-f993-4c5c-d537-0900f21cc974"
      },
      "source": [
        "bilinear_interpolation(coord, img)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32.5000, 36.5000, 40.5000, 44.5000, 48.5000, 52.5000, 56.5000, 60.5000,\n",
              "        64.5000, 68.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}